"""
This code allows the read the file 'percentages_experimental_cell_types.xlsx' to get the % of the different cell types obtained experimentally.
To run it, please chose the lamina (see just below) and run the full code.
It will generate a folder named "solutions laminaX" (X depends on the lamina chosen).
In this folder, the solutions of the algorithm will stored (one csv file per solution found).
In a given csv file, the first column represent the 1000 cells in control condition in the form [B,S,P,H,C]. Each letter can be a -1 (modality not present), 0 (modality present but inhibited) or 1 (modality expressed). The second column are the same cells but in cuff condition (after disinhibition of some modalities).
The control condition is generated from the experimental data, respecting the % of the various modalities in control and disinhibited condition. The cuff condition is generated by iterative partial disinhibition (some 0 turned to 1 in some cells) of the control condition until we obtain the % of modalities in experimental cuff condition.
Both control and cuff condition are generated with a 30% error margin of the experimental %. It means that if % of cell type X is 5% the max accepted error is 5*30/100=1.5%. Therefore, a % btw 3.5% and 6.5% will be considered OK.

In this code lamina1 represents lamina I-IIo of dorsal horn, lamina2 is lamina IIi, lamina3 is lamina III-V
Importantly, in this code cuff and CCI are synonymous and for the Dynamic modality, we use the letter 'B' for brush.

Note the code stops when it found 1000 different solutions for a given lamina. It takes several hours to run.
"""


lamina_chosen='1'
#Parameter to determine which lamina is taken into account
#If setted to "all", the % of cell types in entire dorsal horn are computed
#If setted to "1", the % of cell types in lamina I and IIo are computed
#If setted to "2", the % cell types in lamina IIi are computed
#If setted to "3", the % cell types in lamina III-V are computed


import itertools
import numpy as np
import time
import pandas as pd
import random
import math



"Functions used in this code"
#Function to calculate percentage of occurence of an item in a list 
def calculate_perc_in_list(item=0,list_to_calculate=[]):
    percentage = (len([ele for ele in list_to_calculate if ele == item]) / len(list_to_calculate)) * 100
    percentage = round(percentage,n_number_post_coma)
    return percentage


#Function to calculate the cell type (modalities expressed : BSP, SHC, ect..) from the cell code (ex: [0,0,1,1,0])
def calculate_cell_type(cell=[],modalities_list=[]):
    str_type=''
    for input_value,modality in zip(cell,modalities_list):
        if input_value==1:
            str_type=str_type+modality
    if str_type=='':
        str_type='null'
    cell_type=str_type
    return cell_type


#From a list of cells codes (in the form [[0,1,0,1,1][0,1,1,1,1]...]), this function return the dictionnary
# of cell types (in the form, SHC, SPHC, BSP..) as keys and % of occurence of the cell types as values
def create_dict_perc_types(list_cells=[],modalities_list=[],list_all_possible_types=[]):
    list_cells_types=[0]*len(list_cells)
    for ind_cell, cell in enumerate(list_cells):
        cell_type=calculate_cell_type(cell=cell,modalities_list=modalities_list)
        list_cells_types[ind_cell]=cell_type
    dict_percentage_types={}
    for possible_cell_type in list_all_possible_types:
        percentage = calculate_perc_in_list(item=possible_cell_type,list_to_calculate=list_cells_types)
        dict_percentage_types[possible_cell_type]=percentage
    return dict_percentage_types


#Function to calculate, for a given cell type, the error between the experimental % in CCI network
#and the % in the network tested. Error is assumed to be 0 if below 1% and/or if below a precision level defined 
def calculate_err(dict_percentage_types_CCI={},dict_test={},cell_type='',precision_level=0):
    err = round(dict_percentage_types_CCI[cell_type]-dict_test[cell_type],n_number_post_coma)
    accepted_err=dict_percentage_types_CCI[cell_type]*precision_level
    if accepted_err<1 and accepted_err>0:
        accepted_err=1
    accepted_err=round(accepted_err,n_number_post_coma)
    if err>=-accepted_err and err<=accepted_err:
        err = 0
    else:
        if err>0:
            err=err-accepted_err
        elif err<0:
            err=err+accepted_err
    err = round(err,n_number_post_coma)
    return err


#Function to calculate the total error between two networks
def compare_two_perc_dict(dict_test={},dict_ref={},precision_level=0):
    count_perc_diff=0
    for cell_type in dict_ref.keys():
        err = calculate_err(dict_percentage_types_CCI=dict_ref,
                            dict_test=dict_test,
                            cell_type=cell_type,
                            precision_level=precision_level)
        count_perc_diff=count_perc_diff+np.abs(err) 
    return count_perc_diff


#Function to obtain all the paths to reach one node from an another node in a given graph
def BFS_all_paths(graph, start, goal):
    explored = []
    # Queue for traversing the graph in the BFS
    queue = [[start]]
    # If the desired node is reached
    if start == goal:
        return [[start]]
    # List to store all the possible paths
    all_paths = []
    # Loop to traverse the graph with the help of the queue
    while queue:
        path = queue.pop(0)
        node = path[-1]
        # Condition to check if the current node is not visited
        if node not in explored:
            neighbours = graph[node]
            # Loop to iterate over the neighbours of the node
            for neighbour in neighbours:
                new_path = list(path)
                new_path.append(neighbour)
                queue.append(new_path)
                # Condition to check if the neighbour node is the goal
                if neighbour == goal:
                    all_paths.append(new_path)
                    queue.remove(new_path)
            explored.append(node)
    return all_paths











"Define the parameters to run the code"

n_number_post_coma=1
#chose the precision for the % of cell types in term of number after coma
precision_level=30/100
#chose the precision level to calculate the max accepted error (if % of cell type X is 5% and precision level 30%; the max
#accepted error is 5*30/100=1.5%. Therefore, % btw 3.5% and 6.5% will be considered OK)
n_cells_in_networks=1000
#number of cells in the simulated lamina


 
    
   
   




#List of possible sensory modalities expressed by a given cell : Bruch (=Dynamic), Static, Pinch, Cold and Hot
modalities_list = ['B', 'S', 'P', 'H', 'C']

#list of all possible cell codes in the form (ex : [0,1,0,1,0]).
#A cell is represented by a list of 5 numbers, representing the 5 sensory modalities.
#The numbers can be 1, 0 or -1.
#A 1 at the first position, mean the modality "D" is expressed by the cell. A 0 at this position means this modality is not expressed
#but can be expressed through disinhibition. A "-1" means this modality cannot be expressed, even through disinhibition. 
list_all_possible_cells = [list(i) for i in itertools.product([0, 1,-1], repeat=5)]

#list of all possible cell types in the form (null,BSP,B,BSPHC...).
#Cell type "null" means no modality is expressed (Silent cells)
n_comb=0
for k in range(len(modalities_list)+1):
    n_comb=n_comb+math.comb(len(modalities_list), k)
list_all_possible_types=[0]*n_comb
ind_comb=0
for L in range(len(modalities_list) + 1):
    for subset in itertools.combinations(modalities_list, L):
        str_type=''
        for ele in subset:
            str_type=str_type+str(ele)
        if str_type=='':
            str_type='null'
        list_all_possible_types[ind_comb]=str_type
        ind_comb=ind_comb+1




#extract % of different cell type in control, control after disinhibition or CCI
#Extraction is made from an excel file that contains different sheets. In each box of this file, you will find a cell type and,
#betwenn brackets, the % of this cell type.
#For the sheets pre_post CON all, pre_post CON lamina 1, pre_post CON lamina 2, pre_post CON lamina 3, the first value of each column corresponds
#to the % of the cell type in the lamina considered before disinhibition. The others value of the column, correspond to the transformations of this cell type
# after disinhibition. For example, if the first value of the column is "null (69.74)", it means that 69.74% of the cells of this lamina are Silent.
#If the second value of the same column is "null (41.20)", it means that 41.2% of these Silent cells stay Silent after disinhibition. If the third value
#of the same column is "BSP (10.50)", it means that 10.5% of these Silent cells express the modalities B, S and P after disinhibition, ect...
#For the sheets post_pre CON all, post_pre CON lamina 1, post_pre CON lamina 2, post_pre CON lamina 3, the first value of each column corresponds
#to the % of the cell type in the lamina considered after disinhibition. The others value of the column, correspond to the origin of this cell type
# before disinhibition. For example, if the first value of the column is "BSP (9.51)", it means that 9.51% of the cells of this lamina express B, S and P after disinhibition.
#If the second value of the same column is "null (77.00)", it means that 77% of these BSP cells were Silent before disinhibition. If the third value
#of the same column is "P (11.00)", it means that 11% of these Silent cells express only the modality P before disinhibition, ect...
dict_df = pd.read_excel('percentages_experimental_cell_types.xlsx', 
                   sheet_name=['pre_post_CON','post_pre_CON','CCI','pre_post_CON lam 1','post_pre_CON lam 1','CCI lam 1','pre_post_CON lam 2','post_pre_CON lam 2','CCI lam 2','pre_post_CON lam 3','post_pre_CON lam 3','CCI lam 3'])
pre_post_con_df = dict_df.get('pre_post_CON')
post_pre_con_df = dict_df.get('post_pre_CON')
cci_df = dict_df.get('CCI')
pre_post_con_df_lam1 = dict_df.get('pre_post_CON lam 1')
post_pre_con_df_lam1 = dict_df.get('post_pre_CON lam 1')
cci_df_lam1 = dict_df.get('CCI lam 1')
pre_post_con_df_lam2 = dict_df.get('pre_post_CON lam 2')
post_pre_con_df_lam2 = dict_df.get('post_pre_CON lam 2')
cci_df_lam2 = dict_df.get('CCI lam 2')
pre_post_con_df_lam3 = dict_df.get('pre_post_CON lam 3')
post_pre_con_df_lam3 = dict_df.get('post_pre_CON lam 3')
cci_df_lam3 = dict_df.get('CCI lam 3')



#chose lamina treated : all DH, lamina 1, 2 or 3
if lamina_chosen=='all':
    df_post=post_pre_con_df
    df_pre=pre_post_con_df
    df_cci=cci_df
elif lamina_chosen=='1':
    df_post=post_pre_con_df_lam1
    df_pre=pre_post_con_df_lam1
    df_cci=cci_df_lam1
elif lamina_chosen=='2':
    df_post=post_pre_con_df_lam2
    df_pre=pre_post_con_df_lam2
    df_cci=cci_df_lam2
elif lamina_chosen=='3':
    df_post=post_pre_con_df_lam3
    df_pre=pre_post_con_df_lam3
    df_cci=cci_df_lam3

            
    
    



    
start = time.time()


#construct dict for % of each cell type in control condition before disinhibition
dict_percentage_types_control={}
for index_col,col_name in enumerate(df_pre.columns.values.tolist()):
    splitted=col_name.split('(')
    prebicu_cell_type=splitted[0].replace(' ','')
    perc_prebicu_cell_type=splitted[1].replace(')','')
    perc_prebicu_cell_type=float(perc_prebicu_cell_type)
    perc_prebicu_cell_type = round(perc_prebicu_cell_type,n_number_post_coma)
    dict_percentage_types_control[prebicu_cell_type] = perc_prebicu_cell_type


#Chose the rounding threshold that bring the sum of percentages of different cell codes in control network the closest to 100%
list_threshold_rounding=[]
list_err_sum_perc=[]
for threshold_rounding in range(10,90):
    threshold_rounding=threshold_rounding/100
    sum_perc=0
    for index_col,col_name in enumerate(df_post.columns.values.tolist()):
        splitted=col_name.split('(')
        postbicu_cell_type=splitted[0].replace(' ','')
        perc_postbicu_cell_type=splitted[1].replace(')','')
        perc_postbicu_cell_type=float(perc_postbicu_cell_type)/100
        for ele1 in df_post.loc[:,col_name]:
            if type(ele1)==str:
                splitted=ele1.split('(')
                prebicu_cell_type=splitted[0].replace(' ','')
                perc_prebicu_cell_type=splitted[1].replace(')','')
                perc_prebicu_cell_type=float(perc_prebicu_cell_type)/100
                perc_cell_possibility=perc_postbicu_cell_type*perc_prebicu_cell_type
                perc_cell_possibility=perc_cell_possibility*1000
                perc_cell_possibility=math.ceil(perc_cell_possibility-threshold_rounding)
                perc_cell_possibility=perc_cell_possibility/10
                sum_perc=sum_perc+perc_cell_possibility
    list_threshold_rounding.append(threshold_rounding)
    list_err_sum_perc.append(np.abs(100-sum_perc))
ind_min_err=np.argmin(list_err_sum_perc)
thresh_to_take=list_threshold_rounding[ind_min_err]
threshold_rounding=thresh_to_take

#Built the dictionnary btw all possible cell codes (in the form [0,1,0,0,1]) and their percentages in control network
#using the previously defined threshold_rounding
dict_cell_possibility_control={}
for cell_possibility in list_all_possible_cells:
    dict_cell_possibility_control[str(cell_possibility)]=0
for index_col,col_name in enumerate(df_post.columns.values.tolist()):
    splitted=col_name.split('(')
    postbicu_cell_type=splitted[0].replace(' ','')
    perc_postbicu_cell_type=splitted[1].replace(')','')
    perc_postbicu_cell_type=float(perc_postbicu_cell_type)/100
    for ele1 in df_post.loc[:,col_name]:
        if type(ele1)==str:
            splitted=ele1.split('(')
            prebicu_cell_type=splitted[0].replace(' ','')
            perc_prebicu_cell_type=splitted[1].replace(')','')
            perc_prebicu_cell_type=float(perc_prebicu_cell_type)/100
            perc_cell_possibility=perc_postbicu_cell_type*perc_prebicu_cell_type
            cell=[]
            for modality in modalities_list:
                if modality in postbicu_cell_type and modality in prebicu_cell_type:
                    cell.append(1)
                elif modality in postbicu_cell_type and modality not in prebicu_cell_type:
                    cell.append(0)
                else:
                    cell.append(-1)
            str_cell_possibility=str(cell)
            perc_cell_possibility=perc_cell_possibility*1000
            perc_cell_possibility=math.ceil(perc_cell_possibility-threshold_rounding)
            perc_cell_possibility=perc_cell_possibility/10
            dict_cell_possibility_control[str_cell_possibility]=perc_cell_possibility
     
        
#Built the dictionnary btw cell types (in the form BSP, B, S, BP...) and their percentages in CCI network
dict_percentage_types_CCI={}
for ele in list_all_possible_types:
    dict_percentage_types_CCI[ele]=0.0
for index_col,col_name in enumerate(df_cci.columns.values.tolist()):
    splitted=col_name.split('(')
    CCI_cell_type=splitted[0].replace(' ','')
    perc_CCI_cell_type=splitted[1].replace(')','')
    perc_CCI_cell_type=float(perc_CCI_cell_type)
    perc_CCI_cell_type=round(perc_CCI_cell_type,n_number_post_coma)
    dict_percentage_types_CCI[CCI_cell_type]=perc_CCI_cell_type
    
    

#Built the dictionnary btw all possible cell code (in the form [0,1,0,0,1]) and their possible cell type
#(in the form BSP, B, S, BP...) following partial or total disinhibition (disinhibition means 0's turns into 1's).
dict_possible_cell_types_of_cells={}
list_all_possible_cells = [list(i) for i in itertools.product([0, 1,-1], repeat=5)]
for cell in list_all_possible_cells:
    list_possible_modality=[]
    for syn,modality in zip(cell,modalities_list):
        if syn!=-1:
            list_possible_modality.append(modality)
    list_possible_types=[]
    for L in range(len(list_possible_modality) + 1):
        for subset in itertools.combinations(list_possible_modality, L):
            str_type=''
            for ele in subset:
                str_type=str_type+str(ele)
            if str_type=='':
                str_type='null'
            list_possible_types.append(str_type)
    list_modalities_to_keep=[]
    for ind_syn,syn in enumerate(cell):
        if syn==1:
            list_modalities_to_keep.append(modalities_list[ind_syn])
    list_trans=list_possible_types.copy()
    for modality_to_keep in list_modalities_to_keep:
        for possible_cell_type in list_possible_types:
            if modality_to_keep not in possible_cell_type and possible_cell_type in list_trans:
                list_trans.remove(possible_cell_type)
    list_possible_types=list_trans.copy()
    dict_possible_cell_types_of_cells[str(cell)]=list_possible_types

        
#Built the list of the accepted error for the % of the cells codes in control network, depending on the precision level chosen.   
list_accepted_err=[] 
list_perc_control_cells=[]
list_str_cell_possibility_control=[]
for cell_possibility in dict_cell_possibility_control.keys():
    accepted_err=dict_cell_possibility_control[cell_possibility]*precision_level
    if accepted_err<1  and accepted_err>0:
        accepted_err=1
    accepted_err=round(accepted_err,n_number_post_coma)
    list_accepted_err.append(accepted_err)
    list_perc_control_cells.append(dict_cell_possibility_control[cell_possibility])
    list_str_cell_possibility_control.append(cell_possibility)
     


list_best_CCI_networks=[]
list_best_dist=[]
list_best_mut_count=[]
list_list_cells_control=[]
final_list_control=[]
final_list_CCI=[]

lim_good_answer=0.1
nsubtrial=1
nsubtrial_max=1000
n_solutions_max=1000
if lamina_chosen=='1' or lamina_chosen=='2' or lamina_chosen=='all':
    dist_to_start_subtrial=0.9
elif lamina_chosen=='3':
    dist_to_start_subtrial=1.5

best_dist=10000
solution_nb=0

for trial in range(10000):
    
    print()
    print('nb of solutions found: ',solution_nb)
    
    print()
    print('trial: ',trial)
    
    dist_test=10000
    
    count_no_change_subtrial=0
    for subtrial in range(nsubtrial):
        
        print('trial: ',trial)
        print('subtrial: ',subtrial)
        
        if nsubtrial==1:
            
            #if nsubtrial==1, we construct the dict and the list of control cells codes ("control network") based on the % of the
            #cells recorded experimentally taking into account the error margin of 30%.
            count_perc_diff=1000
            count_big_loop=0
            while count_perc_diff!=0:
                list_effective_err=[0]*len(list_accepted_err)
                for index,ele in enumerate(list_accepted_err):
                    list_effective_err[index]=round(np.random.uniform(-ele,ele),n_number_post_coma)
                sum_err=round(sum(list_effective_err),n_number_post_coma)
                count_loop=0
                while sum_err!=0:
                    index=np.random.randint(0,len(list_effective_err)-1)
                    if sum_err>0:
                        increment=-0.1
                    else:
                        increment=0.1
                    new_err=list_effective_err[index]+increment
                    accepted_err=list_accepted_err[index]
                    if new_err<=accepted_err and new_err>=-accepted_err:
                        list_effective_err[index]=new_err
                    sum_err=round(sum(list_effective_err),n_number_post_coma)
                    count_loop=count_loop+1
                    if count_loop>10000:
                        break
                if count_loop>10000:
                    count_big_loop=count_big_loop+1
                    break
                list_perc_control_cells_with_err=list_perc_control_cells.copy()
                for index,err in enumerate(list_effective_err):
                    list_perc_control_cells_with_err[index]=round(list_perc_control_cells_with_err[index]+err,n_number_post_coma)
                dict_cell_possibility_control_with_err={}
                for index,str_cell_possibility in enumerate(list_str_cell_possibility_control):
                    dict_cell_possibility_control_with_err[str_cell_possibility]=list_perc_control_cells_with_err[index]        
                list_cells_control=[]
                for str_cell_possibility in dict_cell_possibility_control_with_err.keys():
                    cell=[]
                    for ele in str_cell_possibility.split(','):
                        if ele[1]=='-':
                            cell.append(int(ele[1]+ele[2]))
                        else:
                            cell.append(int(ele[1]))
                    n_cell_possibility=int(dict_cell_possibility_control_with_err[str_cell_possibility]*n_cells_in_networks/100)
                    for _ in range(n_cell_possibility):
                        list_cells_control.append(cell)
                dict_control_obtained=create_dict_perc_types(list_cells=list_cells_control,
                                                             modalities_list=modalities_list,
                                                             list_all_possible_types=list_all_possible_types)
                count_perc_diff = compare_two_perc_dict(dict_test=dict_control_obtained,
                                      dict_ref=dict_percentage_types_control,
                                      precision_level=precision_level)
                count_big_loop=count_big_loop+1
                if count_big_loop>10000:
                    break
            if count_loop>10000 or count_big_loop>10000:
                print('list control NOT created!!')
                continue     
            print('list control created!!')
            
        elif nsubtrial==nsubtrial_max:
            
            #if nsubtrial==nsubtrial_max, we construct the dict and the list of control cells codes ("control network") based on the % of the
            #cells recorded experimentally taking into account the error margin of 30%.
            #In this case, the algorithm has previously found a close solution btw control and CCI network. Therefore, the control
            #dict is not constructed from scratch, it take the previous control dict and modify just it by adding one cell to a given cell code
            #and removing one cell from an other cell code (keeping the modifications inside the error margin accepted), hoping
            #that this new control dict will be able to improve the solution for the transformation of control to CCI.
            count_perc_diff=1000
            while count_perc_diff!=0:
                list_effective_err=prev_list_effective_err.copy()
                switch_done=False
                count_loop=0
                while switch_done==False:
                    index1=np.random.randint(0,len(list_effective_err)-1)
                    index2=np.random.randint(0,len(list_effective_err)-1)
                    if index1!=index2:
                        new_err1=list_effective_err[index1]+0.1
                        accepted_err1=list_accepted_err[index1]
                        new_err2=list_effective_err[index2]-0.1
                        accepted_err2=list_accepted_err[index2]
                        if new_err1<=accepted_err1 and new_err1>=-accepted_err1 and new_err2<=accepted_err2 and new_err2>=-accepted_err2:
                            list_effective_err[index1]=new_err1
                            list_effective_err[index2]=new_err2
                            switch_done=True     
                    count_loop=count_loop+1
                    if count_loop>100000:
                        break
                if count_loop>100000:
                    break
                list_perc_control_cells_with_err=list_perc_control_cells.copy()
                for index,err in enumerate(list_effective_err):
                    list_perc_control_cells_with_err[index]=round(list_perc_control_cells_with_err[index]+err,n_number_post_coma)   
                dict_cell_possibility_control_with_err={}
                for index,str_cell_possibility in enumerate(list_str_cell_possibility_control):
                    dict_cell_possibility_control_with_err[str_cell_possibility]=list_perc_control_cells_with_err[index]       
                list_cells_control=[]
                for str_cell_possibility in dict_cell_possibility_control_with_err.keys():
                    cell=[]
                    for ele in str_cell_possibility.split(','):
                        if ele[1]=='-':
                            cell.append(int(ele[1]+ele[2]))
                        else:
                            cell.append(int(ele[1]))
                    n_cell_possibility=int(dict_cell_possibility_control_with_err[str_cell_possibility]*n_cells_in_networks/100)
                    for _ in range(n_cell_possibility):
                        list_cells_control.append(cell)
                dict_control_obtained=create_dict_perc_types(list_cells=list_cells_control,
                                                             modalities_list=modalities_list,
                                                             list_all_possible_types=list_all_possible_types)
                count_perc_diff = compare_two_perc_dict(dict_test=dict_control_obtained,
                                      dict_ref=dict_percentage_types_control,
                                      precision_level=precision_level)
            if count_loop>100000:
                print('list control NOT created!!')
                continue     
            print('list control created!!')
            
            

        #create dict of perc for cell types in the previously created control cell codes list
        list_to_test=list_cells_control.copy()
        dict_test=create_dict_perc_types(list_cells=list_to_test,modalities_list=modalities_list,list_all_possible_types=list_all_possible_types)
        
        #create the list of the cell types for each cell of the control network, and the corresponding potential cell types
        #for each cell of the control network
        list_cell_types_network=[0]*len(list_to_test)
        list_possible_cell_types_network=[0]*len(list_to_test)
        for index,cell in enumerate(list_to_test):
            cell_type=calculate_cell_type(cell=cell,modalities_list=modalities_list)
            possible_cell_types=dict_possible_cell_types_of_cells[str(cell)]
            list_cell_types_network[index]=cell_type
            list_possible_cell_types_network[index]=possible_cell_types
        
        count_no_change=0
        prev_dist_test=1000
        while count_no_change<40:
            
            #list_cell_type_to_drain is the list of cell types that present a bigger % compared to the desired %
            #list_cell_type_to_fill is the list of cell types that present a smaller % compared to the desired %
            #list_cell_type_no_err is the list of cell types that present the desired %
            list_cell_type_to_fill=[]
            list_cell_type_no_err=[]
            list_cell_type_to_drain=[]
            for ele in dict_test.keys():
                err = calculate_err(dict_percentage_types_CCI=dict_percentage_types_CCI,
                                    dict_test=dict_test,
                                    cell_type=ele,
                                    precision_level=precision_level)
                if err>0:
                    list_cell_type_to_fill.append(ele)
                elif err==0:
                    list_cell_type_no_err.append(ele)
                elif err<0:
                    list_cell_type_to_drain.append(ele)
            
        
            #list_cell_type_no_err_to_fill is the list of cell type that would keep the desired % even if we add 1 cell to this cell type
            #list_cell_type_no_err_to_fill is the list of cell type that would keep the desired % even if we remove 1 cell from this cell type
            list_cell_type_no_err_to_fill=[]
            list_cell_type_no_err_to_drain=[]
            for ele in list_cell_type_no_err:
                dict_trans=dict_test.copy()
                dict_trans[ele]=dict_trans[ele]+(100/len(list_to_test))
                err = calculate_err(dict_percentage_types_CCI=dict_percentage_types_CCI,
                                    dict_test=dict_trans,
                                    cell_type=ele,
                                    precision_level=precision_level)
                if err==0:
                    list_cell_type_no_err_to_fill.append(ele)
                dict_trans=dict_test.copy()
                dict_trans[ele]=dict_trans[ele]-(100/len(list_to_test))
                err = calculate_err(dict_percentage_types_CCI=dict_percentage_types_CCI,
                                    dict_test=dict_trans,
                                    cell_type=ele,
                                    precision_level=precision_level)
                if err==0:
                    list_cell_type_no_err_to_drain.append(ele)


            #Create the dict btw cell types and possible cell types in the tested network
            dict_cell_types_possible_cell_types={}
            for cell_type in dict_test:
                dict_cell_types_possible_cell_types[cell_type]=[]
            for cell_type,possible_cell_types in zip(list_cell_types_network,list_possible_cell_types_network):
                for possible_cell_type in possible_cell_types:
                    if possible_cell_type not in dict_cell_types_possible_cell_types[cell_type]:
                        list_trans=dict_cell_types_possible_cell_types[cell_type].copy()
                        list_trans.append(possible_cell_type)
                        dict_cell_types_possible_cell_types[cell_type]=list_trans.copy()
            

            #graph represent all the possible transformations from a cell type to an other in our tested network
            graph = dict_cell_types_possible_cell_types
            list_of_path=[]
            
            #find the all the possible transformations paths between the cell types to drain (the ones with larger % compared to desired value)
            #and one randomy chosen cell types to fill (the ones with smaller % compared to desired value). If no path is found
            #try top find path from the cell_type_no_err_to_drain (the ones with good % and that can lose 1 cell and keep good %)
            #Then, randomly chose 1 path and apply it by switching the cell types.
            if len(list_cell_type_to_fill)>0:
                cell_type_to_fill=random.sample(list_cell_type_to_fill,1)[0]
                list_of_path=[]
                if len(list_cell_type_to_drain)>0:
                    for cell_type_to_drain in list_cell_type_to_drain:
                        all_paths = BFS_all_paths(graph, cell_type_to_drain, cell_type_to_fill)
                        if len(all_paths)>0:
                            for path in all_paths:
                                list_of_path.append(path.copy())
                if len(list_of_path)==0 and len(list_cell_type_no_err_to_drain)>0:
                    for cell_type_no_err_to_drain in list_cell_type_no_err_to_drain:
                        all_paths = BFS_all_paths(graph, cell_type_no_err_to_drain, cell_type_to_fill)
                        if len(all_paths)>0:
                            for path in all_paths:
                                list_of_path.append(path.copy())
                if len(list_of_path)>0:
                    path_chosen = random.sample(list_of_path,1)[0]
                    for ind in range(len(path_chosen)-1):
                        ind_cell=0
                        for cell_type,possible_cell_type in zip(list_cell_types_network,list_possible_cell_types_network):
                            if cell_type==path_chosen[ind] and path_chosen[ind+1] in possible_cell_type:
                                list_cell_types_network[ind_cell]=path_chosen[ind+1]
                                break  
                            ind_cell=ind_cell+1
            
            #If paths were not found before, find the all the possible transformations paths between one randomly chosen cell types to drain (the ones with larger % compared to desired value)
            #and all the cell types to fill (the ones with smaller % compared to desired value). If no path is found
            #try top find path to the cell_type_no_err_to_fill (the ones with good % and that can gain 1 cell and keep good %)
            #Then, randomly chose 1 path and apply it by switching the cell types.
            if len(list_of_path)==0 and len(list_cell_type_to_drain)>0:
                cell_type_to_drain=random.sample(list_cell_type_to_drain,1)[0]
                list_of_path=[]
                if len(list_cell_type_to_fill)>0:
                    for cell_type_to_fill in list_cell_type_to_fill:
                        all_paths = BFS_all_paths(graph, cell_type_to_drain, cell_type_to_fill)
                        if len(all_paths)>0:
                            for path in all_paths:
                                list_of_path.append(path.copy())
                if len(list_of_path)==0 and len(list_cell_type_no_err_to_fill)>0:
                    for cell_type_no_err_to_fill in list_cell_type_no_err_to_fill:
                        all_paths = BFS_all_paths(graph, cell_type_to_drain, cell_type_no_err_to_fill)
                        if len(all_paths)>0:
                            for path in all_paths:
                                list_of_path.append(path.copy())
                if len(list_of_path)>0:
                    path_chosen = random.sample(list_of_path,1)[0]
                    for ind in range(len(path_chosen)-1):
                        ind_cell=0
                        for cell_type,possible_cell_type in zip(list_cell_types_network,list_possible_cell_types_network):
                            if cell_type==path_chosen[ind] and path_chosen[ind+1] in possible_cell_type:
                                list_cell_types_network[ind_cell]=path_chosen[ind+1]
                                break  
                            ind_cell=ind_cell+1
                            
            #If paths were not found before, find the all the possible transformations between cell_type_no_err_to_fill and cell_type_no_err_to_drain
            #Then, randomly chose 1 path and apply it by switching the cell types.
            if len(list_of_path)==0 and len(list_cell_type_no_err_to_fill)>0 and len(list_cell_type_no_err_to_drain)>0:
                list_of_path=[]
                for cell_type_no_err_to_fill in list_cell_type_no_err_to_fill:
                    for cell_type_no_err_to_drain in list_cell_type_no_err_to_drain:
                        if cell_type_no_err_to_fill!=cell_type_no_err_to_drain:
                            if cell_type_no_err_to_fill not in list_cell_type_no_err_to_drain:
                                all_paths = BFS_all_paths(graph, cell_type_no_err_to_drain, cell_type_no_err_to_fill)
                                if len(all_paths)>0:
                                    for path in all_paths:
                                        list_of_path.append(path.copy())
                if len(list_of_path)>0:
                    path_chosen = random.sample(list_of_path,1)[0]
                    for ind in range(len(path_chosen)-1):
                        ind_cell=0
                        for cell_type,possible_cell_type in zip(list_cell_types_network,list_possible_cell_types_network):
                            if cell_type==path_chosen[ind] and path_chosen[ind+1] in possible_cell_type:
                                list_cell_types_network[ind_cell]=path_chosen[ind+1]
                                break  
                            ind_cell=ind_cell+1


            #calculate the the new % after the transformations applied above and construct the dict linking cell_type and %
            dict_test={}
            list_trans=list_cell_types_network.copy()
            for cell_type in dict_percentage_types_CCI.keys():
                perc = (len([ele for ele in list_trans if ele == cell_type]) / len(list_trans)) * 100
                perc = round(perc,n_number_post_coma)
                dict_test[cell_type]=perc
            
            #calculate the distance btw the tested network % and the desired % after the transformations applied above
            dist_test=0
            for cell_type in dict_percentage_types_CCI.keys():
                err = calculate_err(dict_percentage_types_CCI=dict_percentage_types_CCI,
                                    dict_test=dict_test,
                                    cell_type=cell_type,
                                    precision_level=precision_level)
                dist_cell_type = np.abs(err)
                dist_test=dist_test+dist_cell_type
            dist_test=round(dist_test,n_number_post_coma)
            
            #If the calculated dist has not decreased after the transformations applied above, the variable count_no_change is
            #increased. If count_no_change=40 (40 iterations with no modif of the distance), we stop looking for a better network
            if prev_dist_test==dist_test:
                count_no_change=count_no_change+1
            else:
                count_no_change=0
            
            prev_dist_test=dist_test
            
        
   
        #compute the % of the cell types for the better network found
        dict_test={}
        list_trans=list_cell_types_network.copy()
        for cell_type in dict_percentage_types_CCI.keys():
            perc = (len([ele for ele in list_trans if ele == cell_type]) / len(list_trans)) * 100
            perc = round(perc,n_number_post_coma)
            dict_test[cell_type]=perc

        #compute the distance from desired % for the better network found
        dist_test=0
        for cell_type in dict_percentage_types_CCI.keys():
            err = calculate_err(dict_percentage_types_CCI=dict_percentage_types_CCI,
                                dict_test=dict_test,
                                cell_type=cell_type,
                                precision_level=precision_level)
            dist_cell_type = np.abs(err)
            dist_test=dist_test+dist_cell_type
        dist_test=round(dist_test,n_number_post_coma)
        print(dist_test)

        
        end = time.time()
        print('time of computation: ', (end - start)/60, ' minutes')

        #if distance obtained btw CCI % obtained and % desired is close enough to zero (under dist_to_start_subtrial)
        #we start subtrial in which new control cells list is created from the previous one by switching just one cell
        #from a code to an other, hoping to get closer to a solution.
        if dist_test<dist_to_start_subtrial and nsubtrial==1:
            nsubtrial=nsubtrial_max
            prev_list_cells_control=list_cells_control.copy()
            prev_list_effective_err=list_effective_err.copy()
            temp_best_dist=dist_test
        elif nsubtrial==nsubtrial_max and dist_test<temp_best_dist:
            temp_best_dist=dist_test
            prev_list_cells_control=list_cells_control.copy()
            prev_list_effective_err=list_effective_err.copy()
            count_no_change_subtrial=0
        elif nsubtrial==nsubtrial_max and dist_test>=temp_best_dist:
            count_no_change_subtrial=count_no_change_subtrial+1
            
        if subtrial==nsubtrial_max-1:
            nsubtrial=1
        if count_no_change_subtrial==100:
            nsubtrial=1
            break
        
            
        if dist_test<best_dist:
            best_dist=dist_test
        print('best_dist: ',best_dist)
        
        #If the distance found is smaller than the lim fixed, the found network is considered as Ok
        #and the list of CCI cell codes is created, the research is done
        if dist_test<lim_good_answer:
            ind_cell=0
            for cell,cell_type in zip(list_to_test,list_cell_types_network):
                new_cell=[]
                for syn,modality in zip(cell,modalities_list):
                    if syn==-1:
                        new_cell.append(-1)
                    elif syn!=-1 and modality not in cell_type:
                        new_cell.append(0)
                    elif syn!=-1 and modality in cell_type:
                        new_cell.append(1)
                list_to_test[ind_cell]=new_cell.copy()
                ind_cell=ind_cell+1
            break
    
    #if the distance found is smaller than the lim fixed, the found network is considered as Ok
    #and the control and CCI networks are saved in a csv file
    if dist_test<lim_good_answer:        
        df = pd.DataFrame({'Control': list_cells_control,'CCI':list_to_test})
        df.to_csv("solutions lam"+lamina_chosen+"/solution_nb_"+str(solution_nb)+"_err_"+str(precision_level)+".csv" , index=False,sep=';')            
        solution_nb=solution_nb+1
        nsubtrial=1
    if solution_nb==n_solutions_max:
        break

print()
print('Solutions found!!')